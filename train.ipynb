{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTbPS01VJSGVMp2Su50ici",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navodini1995/datasciencecoursera/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPcrwtlv3YoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py as h5\n",
        "from torch.utils import data\n",
        "\n",
        "class MyDataset(data.Dataset):\n",
        "  def __init__(self, archive, transform=None):\n",
        "        self.archive = h5.File(archive, 'r')\n",
        "        self.labels = self.archive['train_vessels']\n",
        "        self.data = self.archive['train']\n",
        "        self.transform = transform\n",
        "  def __getitem__(self, index):\n",
        "    datum = self.data[index]\n",
        "    if self.transform is not None:\n",
        "        datum = self.transform(datum)\n",
        "    return datum, self.labels[index]\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "  def close(self):\n",
        "    self.archive.close()\n",
        "\n",
        "dataset = MyDataset(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_5t-LwH_awm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import imageio\n",
        "f = h5py.File(data_path)\n",
        "dset = f['train']\n",
        "\n",
        "data = np.array(dset[0,:,:])\n",
        "\n",
        "file = '/content/gdrive/My Drive/DeepRetina/test.png' # or .jpg\n",
        "imageio.imwrite(file, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssEupBkEvTMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0a360f77-f275-4024-bb23-678320807087"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls /content/gdrive/My\\ Drive/DeepRetina/unet_attention/*.ipynb\n",
        "!cat '/content/gdrive/My Drive/DeepRetina/unet_attention/model.ipynb'\n",
        "import sys\n",
        "sys.path.append('gdrive/My Drive/DeepRetina/unet_attention/')\n",
        "#!tar xvf \"gdrive/My Drive/DeepRetina//images_train.tar.gz\"\n",
        "\n",
        "#from networks import define_G, define_D, GANLoss, print_network"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'/content/gdrive/My Drive/DeepRetina/unet_attention/model.ipynb'\n",
            "'/content/gdrive/My Drive/DeepRetina/unet_attention/train.ipynb'\n",
            "{\"nbformat\":4,\"nbformat_minor\":0,\"metadata\":{\"colab\":{\"name\":\"model.ipynb\",\"provenance\":[],\"collapsed_sections\":[],\"authorship_tag\":\"ABX9TyPoIq37R4LRFYZTGeNB/fo+\"},\"kernelspec\":{\"name\":\"python3\",\"display_name\":\"Python 3\"}},\"cells\":[{\"cell_type\":\"code\",\"metadata\":{\"id\":\"HdjVV_ZMcOaB\",\"colab_type\":\"code\",\"colab\":{}},\"source\":[\"# full assembly of the sub-parts to form the complete net\\n\",\"import torch\\n\",\"import torch.nn as nn\\n\",\"import torch.nn.functional as F\\n\",\"\\n\",\"class SCSEBlock(nn.Module):\\n\",\"    def __init__(self, channel, reduction=16):\\n\",\"        super().__init__()\\n\",\"        self.avg_pool = nn.AdaptiveAvgPool2d(1)\\n\",\"        self.channel_excitation = nn.Sequential(nn.Linear(channel, int(channel // reduction)),\\n\",\"                                                nn.ReLU(inplace=True),\\n\",\"                                                nn.Linear(int(channel // reduction), channel))\\n\",\"        self.spatial_se = nn.Conv2d(channel, 1, kernel_size=1,\\n\",\"                                    stride=1, padding=0, bias=False)\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        bahs, chs, _, _ = x.size()\\n\",\"\\n\",\"        # Returns a new tensor with the same data as the self tensor but of a different size.\\n\",\"        chn_se = self.avg_pool(x).view(bahs, chs)\\n\",\"        chn_se = torch.sigmoid(self.channel_excitation(chn_se).view(bahs, chs, 1, 1))\\n\",\"        chn_se = torch.mul(x, chn_se)\\n\",\"        spa_se = torch.sigmoid(self.spatial_se(x))\\n\",\"        spa_se = torch.mul(x, spa_se)\\n\",\"        return torch.add(chn_se, 1, spa_se)\\n\",\"\\n\",\"\\n\",\"class double_conv(nn.Module):\\n\",\"    '''(conv => BN => ReLU) * 2'''\\n\",\"\\n\",\"    def __init__(self, in_ch, out_ch):\\n\",\"        super(double_conv, self).__init__()\\n\",\"        self.conv = nn.Sequential(\\n\",\"            nn.Conv2d(in_ch, out_ch, 3, padding=1),\\n\",\"            nn.BatchNorm2d(out_ch),\\n\",\"            nn.ReLU(inplace=True),\\n\",\"            nn.Conv2d(out_ch, out_ch, 3, padding=1),\\n\",\"            nn.BatchNorm2d(out_ch),\\n\",\"            nn.ReLU(inplace=True)\\n\",\"        )\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        x = self.conv(x)\\n\",\"        return x\\n\",\"\\n\",\"\\n\",\"class inconv(nn.Module):\\n\",\"    def __init__(self, in_ch, out_ch):\\n\",\"        super(inconv, self).__init__()\\n\",\"        self.conv = double_conv(in_ch, out_ch)\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        x = self.conv(x)\\n\",\"        return x\\n\",\"\\n\",\"\\n\",\"class down(nn.Module):\\n\",\"    def __init__(self, in_ch, out_ch):\\n\",\"        super(down, self).__init__()\\n\",\"        self.mpconv = nn.Sequential(\\n\",\"            nn.MaxPool2d(2),\\n\",\"            double_conv(in_ch, out_ch)\\n\",\"        )\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        x = self.mpconv(x)\\n\",\"        return x\\n\",\"\\n\",\"\\n\",\"class up(nn.Module):\\n\",\"    def __init__(self, in_ch, out_ch, bilinear=True):\\n\",\"        super(up, self).__init__()\\n\",\"        if bilinear:\\n\",\"            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\\n\",\"        else:\\n\",\"            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\\n\",\"\\n\",\"        self.conv = double_conv(in_ch, out_ch)\\n\",\"        self.SCSE = SCSEBlock(out_ch)\\n\",\"\\n\",\"    def forward(self, x1, x2):\\n\",\"        x1 = self.up(x1)\\n\",\"        x2 = F.upsample(x2, (x1.size(2), x1.size(3)), mode='bilinear')\\n\",\"        x = torch.cat([x2, x1], dim=1)\\n\",\"        x = self.conv(x)\\n\",\"        x = self.SCSE(x)\\n\",\"        return x\\n\",\"\\n\",\"\\n\",\"class outconv(nn.Module):\\n\",\"    def __init__(self, in_ch, out_ch):\\n\",\"        super(outconv, self).__init__()\\n\",\"        self.conv = nn.Conv2d(in_ch, out_ch, 1)\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        x = self.conv(x)\\n\",\"        return x\\n\",\"\\n\",\"class UNet(nn.Module):\\n\",\"    def __init__(self, n_classes):\\n\",\"        super(UNet, self).__init__()\\n\",\"        self.inc = inconv(3, 64)\\n\",\"        self.down1 = down(64, 128)\\n\",\"        self.down2 = down(128, 256)\\n\",\"        self.down3 = down(256, 512)\\n\",\"        self.down4 = down(512, 512)\\n\",\"        self.up1 = up(1024, 256)\\n\",\"        self.up2 = up(512, 128)\\n\",\"        self.up3 = up(256, 64)\\n\",\"        self.up4 = up(128, 64)\\n\",\"        self.outc = outconv(64, n_classes)\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        print ('x_size',x.size())\\n\",\"        x1 = self.inc(x)\\n\",\"        print(x1.size())\\n\",\"        x2 = self.down1(x1)\\n\",\"        print(x2.size())\\n\",\"        x3 = self.down2(x2)\\n\",\"        print(x3.size())\\n\",\"        x4 = self.down3(x3)\\n\",\"        print(x4.size())\\n\",\"        x5 = self.down4(x4)\\n\",\"        print(x5.size(), x4.size())\\n\",\"        #x4 = F.upsample(x4, (x5.size(2)*2, x5.size(3)*2), mode='bilinear')\\n\",\"        x6 = self.up1(x5, x4)\\n\",\"        #print(x6.size())\\n\",\"        x7 = self.up2(x6, x3)\\n\",\"        #print(x7.size())\\n\",\"        x8 = self.up3(x7, x2)\\n\",\"        #print(x8.size())\\n\",\"        x9 = self.up4(x8, x1)\\n\",\"        #print(x9.size())\\n\",\"        x10 = self.outc(x9)\\n\",\"        #print(x10.size())\\n\",\"        x10 = F.upsample(x10, (x.size(2), x.size(3) ), mode='bilinear')\\n\",\"        return x10\\n\"],\"execution_count\":0,\"outputs\":[]}]}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ82o96eA9WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full assembly of the sub-parts to form the complete net\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SCSEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.channel_excitation = nn.Sequential(nn.Linear(channel, int(channel // reduction)),\n",
        "                                                nn.ReLU(inplace=True),\n",
        "                                                nn.Linear(int(channel // reduction), channel))\n",
        "        self.spatial_se = nn.Conv2d(channel, 1, kernel_size=1,\n",
        "                                    stride=1, padding=0, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        bahs, chs, _, _ = x.size()\n",
        "\n",
        "        # Returns a new tensor with the same data as the self tensor but of a different size.\n",
        "        chn_se = self.avg_pool(x).view(bahs, chs)\n",
        "        chn_se = torch.sigmoid(self.channel_excitation(chn_se).view(bahs, chs, 1, 1))\n",
        "        chn_se = torch.mul(x, chn_se)\n",
        "        spa_se = torch.sigmoid(self.spatial_se(x))\n",
        "        spa_se = torch.mul(x, spa_se)\n",
        "        return torch.add(chn_se, 1, spa_se)\n",
        "\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "        self.SCSE = SCSEBlock(out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x2 = F.upsample(x2, (x1.size(2), x1.size(3)), mode='bilinear')\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        x = self.SCSE(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(3, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256)\n",
        "        self.up2 = up(512, 128)\n",
        "        self.up3 = up(256, 64)\n",
        "        self.up4 = up(128, 64)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print ('x_size',x.size())\n",
        "        \n",
        "        x1 = self.inc(x)\n",
        "        #print(x1.size())\n",
        "        x2 = self.down1(x1)\n",
        "        #print(x2.size())\n",
        "        x3 = self.down2(x2)\n",
        "        #print(x3.size())\n",
        "        x4 = self.down3(x3)\n",
        "        #print(x4.size())\n",
        "        x5 = self.down4(x4)\n",
        "        #print(x5.size(), x4.size())\n",
        "        #x4 = F.upsample(x4, (x5.size(2)*2, x5.size(3)*2), mode='bilinear')\n",
        "        x6 = self.up1(x5, x4)\n",
        "        #print(x6.size())\n",
        "        x7 = self.up2(x6, x3)\n",
        "        #print(x7.size())\n",
        "        x8 = self.up3(x7, x2)\n",
        "        #print(x8.size())\n",
        "        x9 = self.up4(x8, x1)\n",
        "        #print(x9.size())\n",
        "        x10 = self.outc(x9)\n",
        "        #print(x10.size())\n",
        "        x10 = F.upsample(x10, (x.size(2), x.size(3) ), mode='bilinear')\n",
        "        return F.sigmoid(x10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOs_5bVRHRTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#System\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import random\n",
        "#Torch\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision.transforms as standard_transforms\n",
        "import h5py as h5\n",
        "from torch.utils import data\n",
        "import matplotlib.pyplot as plt\n",
        "#from model import UNet\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
        "\n",
        "args = {\n",
        "    'num_class': 1,\n",
        "    'ignore_label': 255,\n",
        "    'num_gpus': 2,\n",
        "    'start_epoch': 1,\n",
        "    'num_epoch': 125,\n",
        "    'batch_size': 1,\n",
        "    'lr': 0.0001,\n",
        "    'lr_decay': 0.9,\n",
        "    'dice': 0,\n",
        "    'weight_decay': 1e-4,\n",
        "    'momentum': 0.9,\n",
        "    'snapshot': '',\n",
        "    'opt': 'adam',\n",
        "    'pred_dir':'/content/gdrive/My Drive/DeepRetina/unet_attention/predicted/',\n",
        "    'ckpt_dir': '/content/gdrive/My Drive/DeepRetina/unet_attention/ckpt/unet_scSE/',\n",
        "}\n",
        "\n",
        "class MyDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, archive, transform=None):\n",
        "        self.archive = h5.File(archive, 'r')\n",
        "        self.labels = self.archive['train_vessels']\n",
        "        self.data = self.archive['train']\n",
        "        self.transform = transform\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    datum = self.data[index]\n",
        "    labels_ = self.labels[index]\n",
        "    if self.transform is not None:\n",
        "        datum = self.transform(datum)\n",
        "    labels_y = preprocess_y(labels_)\n",
        "    labels__ = labels_y[None,:,:]\n",
        "    datum_x = preprocess_x(datum).transpose(2,0,1)\n",
        "    return datum_x, labels__\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "  def close(self):\n",
        "    self.archive.close()\n",
        "\n",
        "def preprocess_y(inputs_):\n",
        "    inputs_ /= 255.\n",
        "    inputs_[inputs_ >= 0.5] = 1\n",
        "    inputs_[inputs_ < 0.5] = 0\n",
        "    return inputs_\n",
        "\n",
        "def preprocess_x(inputs_):\n",
        "    inputs_ /= 255.\n",
        "    return inputs_\n",
        "\n",
        "\n",
        "data_path = '/content/gdrive/My Drive/DeepRetina/Retinal_Work/DeepRetina/datasets/scleral_data/scleral_bbox_vessels_data512.hdf5'\n",
        "\n",
        "dataset = MyDataset(data_path)\n",
        "lengths = [ int(len(dataset)*0.8),int(len(dataset)*0.2)+1]\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset,lengths)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=12, drop_last=True)\n",
        "\n",
        "model = UNet(n_classes=1)\n",
        "gpu_ids = range(args['num_gpus'])\n",
        "#model = torch.nn.parallel.DataParallel(model, device_ids=gpu_ids)\n",
        "model = model.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "if args['opt'] == 'sgd':\n",
        "    optimizer = optim.SGD(model.parameters(),\n",
        "                          lr=0.0002,\n",
        "                          momentum=0.99, weight_decay=0.0001)\n",
        "elif args['opt'] == 'adam':\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                            lr=args['lr'], weight_decay=0.0001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDwhMfbLC-Vq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jrpRwoOgKVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if not os.path.exists(args['ckpt_dir']):\n",
        "    os.makedirs(args['ckpt_dir'])\n",
        "\n",
        "class CrossEntropyLoss2d(torch.nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(CrossEntropyLoss2d, self).__init__()\n",
        "        self.nll_loss = torch.nn.NLLLoss(weight, size_average)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        return self.nll_loss(F.log_softmax(inputs), targets)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #img_dir = '../train_train.txt'\n",
        "\n",
        "    #print(dataset.__len__())\n",
        "\n",
        "\n",
        "    #criterion = CrossEntropyLoss2d(size_average=True).cuda()\n",
        "\n",
        "    model.train()\n",
        "    epoch_iters = dataset.__len__() / args['batch_size']\n",
        "    max_epoch = args['num_epoch']\n",
        "    for epoch in range(max_epoch):\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            inputs = Variable(inputs).cuda().float()\n",
        "            labels = Variable(labels).cuda().float()\n",
        "            \n",
        "            #print(np.unique(inputs.cpu()))\n",
        "            #print(np.shape(labels.cpu()))\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            #print(np.shape(outputs.cpu()))\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (batch_idx + 1) % 20 == 0:\n",
        "                print('[epoch %d], [iter %d / %d], [train main loss %.5f], [lr %.10f]' % (\n",
        "                    epoch, batch_idx + 1, epoch_iters, loss.item(),\n",
        "                    optimizer.param_groups[0]['lr']))\n",
        "\n",
        "        snapshot_name = 'epoch_' + str(epoch)\n",
        "        torch.save(model.state_dict(), os.path.join(args['ckpt_dir'], snapshot_name + '.pth.tar'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz0W5ZWt_2O7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43ac2b65-0741-45b9-bf21-d7d154645cac"
      },
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "  net =  UNet(n_classes=1).cuda()\n",
        "  valid_loader = DataLoader(dataset=valid_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=12, drop_last=True)\n",
        "  #net = torch.nn.parallel.DataParallel(net, device_ids=[0, 1])\n",
        "  #dir = '/media/mmlab/data/Datasets/BraTS/BraTS17/Brats17_valid/BraTS17_valid_mri/**'\n",
        "  #patients = sorted(glob(dir), key=os.path.getmtime)\n",
        "  #IMG_MEAN = np.array((23.661847049902107,23.13533027273353,26.694140535191476),dtype=np.float32)\n",
        "  Best_Dice = 0\n",
        "  Best_epoch=0\n",
        "  \n",
        "  for epochs in range(1,125):\n",
        "\n",
        "    args['snapshot'] = 'epoch_'+ str(epochs) + '.pth.tar'\n",
        "    net.load_state_dict(torch.load(os.path.join(args['ckpt_dir'], args['snapshot'])))\n",
        "    net.eval()\n",
        "    mdice = [];\n",
        "    #scans = list((4,1))\n",
        "    LOSS = 0.0\n",
        "    for batch_idx, data in enumerate(valid_loader):\n",
        "      inputs_val, labels_val = data\n",
        "      inputs_val = Variable(inputs_val).cuda().float()\n",
        "      labels_val = Variable(labels_val).cuda().float()\n",
        "      #print(inputs_val.shape)\n",
        "      outputs_val = net(inputs_val)\n",
        "      #print(np.shape(outputs.cpu()))\n",
        "      loss = criterion(outputs_val, labels_val)\n",
        "      LOSS = LOSS + loss.item()\n",
        "      optimizer.step()\n",
        "    print('epoch',epochs,'Valid_loss',LOSS/(int(len(dataset)*0.2)+1))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 Valid_loss 0.22447436761397582\n",
            "epoch 2 Valid_loss 0.1990153445647313\n",
            "epoch 3 Valid_loss 0.17410715554769224\n",
            "epoch 4 Valid_loss 0.14118102221534803\n",
            "epoch 5 Valid_loss 0.15129176383981338\n",
            "epoch 6 Valid_loss 0.11703395700225463\n",
            "epoch 7 Valid_loss 0.13700002976335013\n",
            "epoch 8 Valid_loss 0.11129966707756886\n",
            "epoch 9 Valid_loss 0.28861361226210225\n",
            "epoch 10 Valid_loss 0.1415068511492931\n",
            "epoch 11 Valid_loss 0.12719159988829723\n",
            "epoch 12 Valid_loss 0.1229397630175719\n",
            "epoch 13 Valid_loss 0.18337813549889967\n",
            "epoch 14 Valid_loss 0.10687271964091521\n",
            "epoch 15 Valid_loss 0.15129604677741343\n",
            "epoch 16 Valid_loss 0.14774045806664687\n",
            "epoch 17 Valid_loss 0.15050934971525118\n",
            "epoch 18 Valid_loss 0.19035358669666144\n",
            "epoch 19 Valid_loss 0.19745644547331792\n",
            "epoch 20 Valid_loss 0.13203105086890551\n",
            "epoch 21 Valid_loss 0.1697125886208736\n",
            "epoch 22 Valid_loss 0.1273140087723732\n",
            "epoch 23 Valid_loss 0.15998938135229623\n",
            "epoch 24 Valid_loss 0.13806088927846688\n",
            "epoch 25 Valid_loss 0.16905801069851106\n",
            "epoch 26 Valid_loss 0.09314394971499076\n",
            "epoch 27 Valid_loss 0.2574546062029325\n",
            "epoch 28 Valid_loss 0.18339339113579348\n",
            "epoch 29 Valid_loss 0.2626499025007853\n",
            "epoch 30 Valid_loss 0.09679934690491511\n",
            "epoch 31 Valid_loss 0.16084892847217047\n",
            "epoch 32 Valid_loss 0.14309872779995203\n",
            "epoch 33 Valid_loss 0.14415516818945223\n",
            "epoch 34 Valid_loss 0.10966870876458976\n",
            "epoch 35 Valid_loss 0.18122643361297938\n",
            "epoch 36 Valid_loss 0.1810789006547286\n",
            "epoch 37 Valid_loss 0.26142013946977943\n",
            "epoch 38 Valid_loss 0.1746594665142206\n",
            "epoch 39 Valid_loss 0.12319191495099893\n",
            "epoch 40 Valid_loss 0.16511225413817626\n",
            "epoch 41 Valid_loss 0.1737250224328958\n",
            "epoch 42 Valid_loss 0.21394718732111728\n",
            "epoch 43 Valid_loss 0.1150932890864519\n",
            "epoch 44 Valid_loss 0.12300038244575262\n",
            "epoch 45 Valid_loss 0.1555309298519905\n",
            "epoch 46 Valid_loss 0.21385364363399836\n",
            "epoch 47 Valid_loss 0.18353494700904077\n",
            "epoch 48 Valid_loss 0.28458681910370404\n",
            "epoch 49 Valid_loss 0.23608740920630786\n",
            "epoch 50 Valid_loss 0.1148146684639729\n",
            "epoch 51 Valid_loss 0.11517348269430491\n",
            "epoch 52 Valid_loss 0.16309709968761757\n",
            "epoch 53 Valid_loss 0.19259141679280078\n",
            "epoch 54 Valid_loss 0.17309301984138215\n",
            "epoch 55 Valid_loss 0.18450329151864236\n",
            "epoch 56 Valid_loss 0.25265767188886035\n",
            "epoch 57 Valid_loss 0.22930239800077218\n",
            "epoch 58 Valid_loss 0.11276532143640977\n",
            "epoch 59 Valid_loss 0.1332963928580284\n",
            "epoch 60 Valid_loss 0.13588459352747753\n",
            "epoch 61 Valid_loss 0.17701691166999248\n",
            "epoch 62 Valid_loss 0.19324440552065006\n",
            "epoch 63 Valid_loss 0.11281104722561744\n",
            "epoch 64 Valid_loss 0.12239256014044468\n",
            "epoch 65 Valid_loss 0.22322174362265146\n",
            "epoch 66 Valid_loss 0.22357869004974\n",
            "epoch 67 Valid_loss 0.14422838841206753\n",
            "epoch 68 Valid_loss 0.19179894753660148\n",
            "epoch 69 Valid_loss 0.1251522688768231\n",
            "epoch 70 Valid_loss 0.23501744329069668\n",
            "epoch 71 Valid_loss 0.14811544671941262\n",
            "epoch 72 Valid_loss 0.13375135582800096\n",
            "epoch 73 Valid_loss 0.21416766425737968\n",
            "epoch 74 Valid_loss 0.2748335041822149\n",
            "epoch 75 Valid_loss 0.12662102532787964\n",
            "epoch 76 Valid_loss 0.17319392742445835\n",
            "epoch 77 Valid_loss 0.25049862122306454\n",
            "epoch 78 Valid_loss 0.1929652517518172\n",
            "epoch 79 Valid_loss 0.27104485565080094\n",
            "epoch 80 Valid_loss 0.155586442623574\n",
            "epoch 81 Valid_loss 0.12652015155897692\n",
            "epoch 82 Valid_loss 0.1408082228153944\n",
            "epoch 83 Valid_loss 0.21027467765200597\n",
            "epoch 84 Valid_loss 0.09986196243419097\n",
            "epoch 85 Valid_loss 0.20745626349861807\n",
            "epoch 86 Valid_loss 0.17112323154623693\n",
            "epoch 87 Valid_loss 0.2558183644253474\n",
            "epoch 88 Valid_loss 0.11853995475058372\n",
            "epoch 89 Valid_loss 0.12855790405032727\n",
            "epoch 90 Valid_loss 0.13166548734387526\n",
            "epoch 91 Valid_loss 0.2292294128296467\n",
            "epoch 92 Valid_loss 0.20192216279414985\n",
            "epoch 93 Valid_loss 0.2864006352252685\n",
            "epoch 94 Valid_loss 0.1661132235939686\n",
            "epoch 95 Valid_loss 0.09412552065287645\n",
            "epoch 96 Valid_loss 0.1188587976906162\n",
            "epoch 97 Valid_loss 0.18641858619566148\n",
            "epoch 98 Valid_loss 0.20114524168177292\n",
            "epoch 99 Valid_loss 0.10741904077048485\n",
            "epoch 100 Valid_loss 0.18820044971429384\n",
            "epoch 101 Valid_loss 0.11683730265268913\n",
            "epoch 102 Valid_loss 0.14996115977947527\n",
            "epoch 103 Valid_loss 0.34374544855493766\n",
            "epoch 104 Valid_loss 0.12614633766217873\n",
            "epoch 105 Valid_loss 0.14042054804471824\n",
            "epoch 106 Valid_loss 0.2955795894735135\n",
            "epoch 107 Valid_loss 0.17623993281561595\n",
            "epoch 108 Valid_loss 0.16889037034259394\n",
            "epoch 109 Valid_loss 0.09958051059108514\n",
            "epoch 110 Valid_loss 0.12221157142462638\n",
            "epoch 111 Valid_loss 0.2851380076116094\n",
            "epoch 112 Valid_loss 0.17519332841038704\n",
            "epoch 113 Valid_loss 0.24796344440143842\n",
            "epoch 114 Valid_loss 0.1818491117312358\n",
            "epoch 115 Valid_loss 0.19715266796545342\n",
            "epoch 116 Valid_loss 0.16424630073687205\n",
            "epoch 117 Valid_loss 0.16409688005940273\n",
            "epoch 118 Valid_loss 0.10600211435499099\n",
            "epoch 119 Valid_loss 0.1842554836319043\n",
            "epoch 120 Valid_loss 0.10917920977450334\n",
            "epoch 121 Valid_loss 0.14954226084340078\n",
            "epoch 122 Valid_loss 0.10472923832444045\n",
            "epoch 123 Valid_loss 0.11718191836888973\n",
            "epoch 124 Valid_loss 0.10152287766910516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_NosUi29E11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fd26f33-19a5-45f9-f9d6-244a636b2d47"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    net =  UNet(n_classes=1).cuda()\n",
        "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=12, drop_last=True)\n",
        "    Best_Dice = 0\n",
        "    Best_epoch=0\n",
        "    for epochs in range(84,85):\n",
        "\n",
        "        args['snapshot'] = 'epoch_'+ str(epochs) + '.pth.tar'\n",
        "        net.load_state_dict(torch.load(os.path.join(args['ckpt_dir'], args['snapshot'])))\n",
        "        net.eval()\n",
        "        mdice = [];\n",
        "        #scans = list((4,1))\n",
        "        #LOSS = 0\n",
        "        for batch_idx, data in enumerate(valid_loader):\n",
        "            inputs_test, labels_test = data\n",
        "            inputs_test = Variable(inputs_test).cuda().float()\n",
        "            labels_test = Variable(labels_test).cuda().float()\n",
        "            outputs_test = net(inputs_test)\n",
        "            #print(np.shape(outputs.cpu()))\n",
        "            #loss = criterion(outputs, labels)\n",
        "            #LOSS = LOSS + loss\n",
        "\n",
        "            fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(15, 15))\n",
        "            ax1, ax2, ax3 = ax.ravel()\n",
        "            ax1.imshow(np.squeeze(inputs_test.cpu().detach().numpy()), cmap='jet')\n",
        "            ax1.set_title('Retinal Image')\n",
        "            ax2.imshow(np.squeeze(labels_test.cpu().detach().numpy()))\n",
        "            ax2.set_title('Annontated Vessels')\n",
        "            ax3.imshow(np.squeeze(outputs_test.cpu().detach().numpy()))\n",
        "            ax3.set_title('Reconstructed Vessels')\n",
        "            plt.show()\n",
        "            #print('epoch',epochs,'Valid_loss',LOSS/(int(len(dataset)*0.2)+1))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-018e3451dad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retinal Image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5613\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5615\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5616\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 512, 512) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAANOCAYAAABUbz43AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naOAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc35wBmgHj9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}